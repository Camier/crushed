{
  "$schema": "https://charm.land/crush.json",
  "providers": {
    "vllm": {
      "name": "vLLM (OpenAI compatible, local GPU)",
      "base_url": "http://127.0.0.1:8000/v1/",
      "type": "openai",
      "models": [
        {
          "name": "Llama 3 8B Instruct",
          "id": "meta-llama/Meta-Llama-3-8B-Instruct",
          "context_window": 8192,
          "default_max_tokens": 1024
        }
      ]
    },
    "llamacpp-14b": {
      "name": "llama.cpp Qwen2.5 14B (local)",
      "base_url": "http://127.0.0.1:8080/v1/",
      "type": "openai",
      "disable_stream": true,
      "models": [
        {
          "name": "Qwen2.5-14B-Instruct",
          "id": "qwen2.5-14b-instruct",
          "context_window": 32768,
          "default_max_tokens": 1024
        }
      ]
    },
    "llama-qwen7b": {
      "name": "llama.cpp Qwen 7B (32k)",
      "base_url": "http://127.0.0.1:8081/v1/",
      "type": "openai",
      "models": [
        {
          "name": "Qwen2.5-7B-Instruct",
          "id": "qwen2.5-7b-instruct",
          "context_window": 32768,
          "default_max_tokens": 1024
        }
      ]
    },
    "llama-dolphin7b": {
      "name": "llama.cpp Dolphin 7B (uncensored, 32k)",
      "base_url": "http://127.0.0.1:8082/v1/",
      "type": "openai",
      "disable_stream": true,
      "models": [
        {
          "name": "dolphin-2.9.3-mistral-7B-32k",
          "id": "dolphin-2.9.3-mistral-7b-32k",
          "context_window": 32768,
          "default_max_tokens": 1024
        }
      ]
    },
    "llama-coder7b": {
      "name": "llama.cpp Qwen Coder 7B (32k)",
      "base_url": "http://127.0.0.1:8083/v1/",
      "type": "openai",
      "models": [
        {
          "name": "Qwen2.5-Coder-7B-Instruct",
          "id": "qwen2.5-coder-7b-instruct",
          "context_window": 32768,
          "default_max_tokens": 1024
        }
      ]
    },
    "ollama": {
      "name": "Ollama (OpenAI compatible)",
      "base_url": "http://127.0.0.1:11434/v1/",
      "type": "openai",
      "disable_stream": true,
      "models": [
        {
          "name": "Qwen2.5 Coder 7B",
          "id": "qwen2.5-coder:7b",
          "context_window": 8192,
          "default_max_tokens": 1024
        }
      ]
    },
    "llama-nous13b": {
      "name": "llama.cpp Nous Hermes 13B Uncensored",
      "base_url": "http://127.0.0.1:8084/v1/",
      "type": "openai",
      "disable_stream": true,
      "models": [
        {
          "name": "Nous-Hermes Llama-2 13B Uncensored",
          "id": "nous-hermes-13b-uncensored",
          "context_window": 4096,
          "default_max_tokens": 1024
        }
      ]
    },
    "llama-airoboros13b": {
      "name": "llama.cpp Airoboros L2 13B 2.2 Uncensored",
      "base_url": "http://127.0.0.1:8085/v1/",
      "type": "openai",
      "disable_stream": true,
      "models": [
        {
          "name": "Airoboros L2 13B 2.2 Uncensored",
          "id": "airoboros-l2-13b-2.2-uncensored",
          "context_window": 4096,
          "default_max_tokens": 1024
        }
      ]
    },
    "llama-wizard13b": {
      "name": "llama.cpp WizardLM 13B Uncensored",
      "base_url": "http://127.0.0.1:8086/v1/",
      "type": "openai",
      "disable_stream": true,
      "models": [
        {
          "name": "WizardLM 13B Uncensored",
          "id": "wizardlm-13b-uncensored",
          "context_window": 4096,
          "default_max_tokens": 1024
        }
      ]
    },
    "llama-mythomax13b": {
      "name": "llama.cpp MythoMax L2 13B",
      "base_url": "http://127.0.0.1:8087/v1/",
      "type": "openai",
      "disable_stream": true,
      "models": [
        {
          "name": "MythoMax-L2 13B",
          "id": "mythomax-l2-13b",
          "context_window": 4096,
          "default_max_tokens": 1024
        }
      ]
    },
    "openai": {
      "name": "OpenAI",
      "base_url": "https://api.openai.com/v1/",
      "type": "openai",
      "api_key": "$OPENAI_API_KEY",
      "models": [
        {
          "name": "GPT-4o",
          "id": "gpt-4o",
          "context_window": 128000,
          "default_max_tokens": 4096
        }
      ]
    },
    "groq": {
      "name": "Groq",
      "base_url": "https://api.groq.com/openai/v1/",
      "type": "openai",
      "api_key": "$GROQ_API_KEY",
      "models": [
        {
          "name": "Llama3-8B-8192",
          "id": "llama3-8b-8192",
          "context_window": 8192,
          "default_max_tokens": 4096
        }
      ]
    },
    "together": {
      "name": "Together AI",
      "base_url": "https://api.together.xyz/v1/",
      "type": "openai",
      "api_key": "$TOGETHER_API_KEY",
      "models": [
        {
          "name": "Llama-3-70B-Instruct",
          "id": "meta-llama/Llama-3-70B-Instruct-Turbo",
          "context_window": 8000,
          "default_max_tokens": 4096
        }
      ]
    },
    "fireworks": {
      "name": "Fireworks AI",
      "base_url": "https://api.fireworks.ai/inference/v1/",
      "type": "openai",
      "api_key": "$FIREWORKS_API_KEY",
      "models": [
        {
          "name": "FireLLaVa 13B",
          "id": "accounts/fireworks/models/firellava-13b",
          "context_window": 8192,
          "default_max_tokens": 2048
        }
      ]
    },
    "dashscope-intl": {
      "name": "DashScope (Intl)",
      "base_url": "https://dashscope-intl.aliyuncs.com/compatible-mode/v1/",
      "type": "openai",
      "api_key": "$DASHSCOPE_API_KEY",
      "models": [
        {
          "name": "Qwen3 Coder Plus",
          "id": "qwen3-coder-plus",
          "context_window": 131072,
          "default_max_tokens": 8192
        }
      ]
    },
    "dashscope-cn": {
      "name": "DashScope (CN)",
      "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1/",
      "type": "openai",
      "api_key": "$DASHSCOPE_API_KEY",
      "models": [
        {
          "name": "Qwen3 Coder Plus",
          "id": "qwen3-coder-plus",
          "context_window": 131072,
          "default_max_tokens": 8192
        }
      ]
    },
    "modelscope-cn": {
      "name": "ModelScope (CN)",
      "base_url": "https://api-inference.modelscope.cn/v1/",
      "type": "openai",
      "api_key": "$MODELSCOPE_API_KEY",
      "models": [
        {
          "name": "Qwen3 Coder 480B Instruct",
          "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
          "context_window": 131072,
          "default_max_tokens": 8192
        }
      ]
    },
    "openrouter": {
      "name": "OpenRouter",
      "base_url": "https://openrouter.ai/api/v1/",
      "type": "openai",
      "api_key": "$OPENROUTER_API_KEY",
      "models": [
        {
          "name": "Qwen3 Coder (Free)",
          "id": "qwen/qwen3-coder:free",
          "context_window": 131072,
          "default_max_tokens": 8192
        }
      ]
    }
  },
  "models": {
    "large": { "model": "qwen2.5-14b-instruct", "provider": "llamacpp-14b" },
    "small": { "model": "dolphin-2.9.3-mistral-7b-32k", "provider": "llama-dolphin7b" }
  },
  "options": {
    "context_paths": [],
    "disabled_tools": [
      "bash",
      "download",
      "edit",
      "multiedit",
      "fetch",
      "glob",
      "grep",
      "ls",
      "sourcegraph",
      "view",
      "write"
    ]
  }
}
